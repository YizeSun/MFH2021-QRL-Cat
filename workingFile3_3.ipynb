{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister\n",
    "from qiskit import Aer, transpile, assemble\n",
    "from qiskit.providers import backend\n",
    "from qiskit.aqua.components.optimizers import COBYLA\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TYPES:\n",
    "CAT = \"c\"\n",
    "# DOG = \"d\"\n",
    "MOUSE = \"m\"\n",
    "EMPTY = \"emp\"\n",
    "\n",
    "# ACTIONS:\n",
    "UP = \"00\"\n",
    "DOWN = \"01\"\n",
    "LEFT = \"10\"\n",
    "RIGHT = \"11\"\n",
    "ACTIONS = [UP, DOWN, LEFT, RIGHT]\n",
    "\n",
    "# random seed\n",
    "random.seed(10)\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state of cat\n",
    "class State:\n",
    "    def __init__(self, catP):\n",
    "        self.row = catP[0]\n",
    "        self.column = catP[1]\n",
    "        self.catP = catP\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, State) and self.row == other.row and self.column == other.column and self.catP == other.catP\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(str(self.catP))\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"State(cat_pos={self.catP})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridWorld\n",
    "# e.g.\n",
    "#  MOUSE | EMPTY | EMPTY\n",
    "#  EMPTY | EMPTY | EMPTY\n",
    "#  EMPTY | EMPTY | CAT\n",
    "class GridWorld:\n",
    "    def __init__(self, s, catP, mouseP):\n",
    "        self.numRows = s[0]\n",
    "        self.numColumns = s[1]\n",
    "        self.catP = catP\n",
    "        self.mouseP = mouseP\n",
    "        # self.dogP = dogP\n",
    "        assert(not self.compaireList(self.catP, self.mouseP))\n",
    "    \n",
    "    def getItem(self, p):\n",
    "        if p[0]>=self.numRows or p[0]<0:\n",
    "            return None\n",
    "        if p[1]>=self.numColumns or p[1]<0:\n",
    "            return None\n",
    "        if self.compaireList(p, catP):\n",
    "            return CAT\n",
    "        elif self.compaireList(p, mouseP):\n",
    "            return MOUSE\n",
    "        # elif self.compaireList(p, DOG):\n",
    "        #     return DOG\n",
    "        else:\n",
    "            return EMPTY\n",
    "\n",
    "    def compaireList(self, l1,l2):\n",
    "        for i, j in zip(l1, l2):\n",
    "            if i!=j:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def getNumRows(self):\n",
    "        return self.numRows\n",
    "\n",
    "    def getNumColumns(self):\n",
    "        return self.numColumns\n",
    "\n",
    "    def getMouse(self):\n",
    "        return self.mouse\n",
    "    \n",
    "    def getCatP(self):\n",
    "        return self.catP\n",
    "\n",
    "    def setCatP(self, p):\n",
    "        self.catP = p\n",
    "        \n",
    "    def setMouseP(self, p):\n",
    "        self.mouseP = p\n",
    "    \n",
    "    def initCatState(self, rd = False):\n",
    "        # init cat position\n",
    "        if not rd:\n",
    "            catP = [self.getNumRows() - 1, self.getNumColumns() - 1]\n",
    "        else:\n",
    "            catP = [random.randint(0, self.getNumRows()), random.randint(0, self.getNumColumns())]\n",
    "            while self.getItem(catP) != EMPTY and self.getItem(catP) != CAT:\n",
    "                catP = [random.randint(0, self.getNumRows()), random.randint(0, self.getNumColumns())]\n",
    "        self.setCatP(catP)\n",
    "        return State(catP)\n",
    "    \n",
    "    def show(self):\n",
    "        output = \"\"\n",
    "        for i in range(self.numRows):\n",
    "            for j in range(self.numColumns):\n",
    "                if self.compaireList([i,j], self.catP):\n",
    "                    output += CAT + \" \"\n",
    "                if self.compaireList([i,j], self.mouseP):\n",
    "                    output += MOUSE + \" \"\n",
    "                if not self.compaireList([i,j], self.catP) and not self.compaireList([i,j], self.mouseP):\n",
    "                    output += EMPTY + \" \"\n",
    "            output += \"\\n\"\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QNet\n",
    "class QNet:\n",
    "    \n",
    "    def __init__(self, qTable, gridWorld:GridWorld, params, alpha=0.1, gamma=1.0, eps=0.2, actions=[UP, DOWN, LEFT, RIGHT]):\n",
    "        \n",
    "        self.params = params # inital parameters are the same for all qNetwork\n",
    "        self.gw = gridWorld\n",
    "        self.qt = qTable\n",
    "        self.eps = eps\n",
    "        self.backend = Aer.get_backend(\"qasm_simulator\")\n",
    "        self.NUM_SHOTS = 1000 # number of measurements \n",
    "        self.optimizer = COBYLA(maxiter=500, tol=0.0001) # off the shelf\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.ACTIONS = actions\n",
    "\n",
    "        # self.rets = {(0,0):([0,..,0],0.0,0), ...}\n",
    "        self.rets = dict() # resulting parameters after optimization for all points in the grid\n",
    "\n",
    "        self.state = None\n",
    "        \n",
    "        for i in range(self.gw.getNumRows()):\n",
    "            for j in range(self.gw.getNumColumns()):\n",
    "                self.rets[i, j] = (self.params, 0.0, 0) \n",
    "    \n",
    "    def qcMaker(self, params):\n",
    "        qr = QuantumRegister(2, name=\"q\")\n",
    "        cr = ClassicalRegister(2, name=\"c\")\n",
    "        qc = QuantumCircuit(qr, cr)\n",
    "        qc.u3(params[0], params[1], params[2], qr[0])\n",
    "        qc.u3(params[3], params[4], params[5], qr[1])\n",
    "        # qc.cx(qr[0], qr[1])\n",
    "        qc.measure(qr, cr)\n",
    "        return qc\n",
    "\n",
    "    def newPosition(self, state, action):\n",
    "        p = deepcopy(state.catP)\n",
    "        if action == UP:\n",
    "            p[0] = max(0, p[0] - 1)\n",
    "        elif action == DOWN:\n",
    "            p[0] = min(self.gw.getNumRows() - 1, p[0]+1)\n",
    "        elif action == LEFT:\n",
    "            p[1] = max(0, p[1] - 1)\n",
    "        elif action == RIGHT:\n",
    "            p[1] = min(self.gw.getNumColumns() - 1, p[1] + 1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unkown action {action}\")\n",
    "        return p\n",
    "        \n",
    "    def getReward(self, p):\n",
    "        grid = self.gw.getItem(p)\n",
    "        if grid == EMPTY:\n",
    "            reward = -1\n",
    "        # elif grid == DOG:\n",
    "        #     reward = -1000\n",
    "        elif grid == MOUSE:\n",
    "            reward = 100\n",
    "        elif grid == CAT:\n",
    "            reward = -1 # (maybe less than reward of empty)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown grid item {grid}\")\n",
    "        return reward\n",
    "    \n",
    "    def selectAction(self, state, training):\n",
    "        if random.uniform(0, 1) < self.eps:\n",
    "            return random.choice(self.ACTIONS)\n",
    "        else:\n",
    "            if training:\n",
    "                self.state = state\n",
    "                self.updateCircuit(state)\n",
    "            return self.ACTIONS[np.argmax(self.qt[self.state.catP[0], self.state.catP[1]])]\n",
    "        \n",
    "    def lossFunction(self, params):\n",
    "        qc = self.qcMaker(params=params)\n",
    "        t_qc = transpile(qc, self.backend)\n",
    "        job = assemble(t_qc, shots=self.NUM_SHOTS)\n",
    "        rlt = self.backend.run(job).result()\n",
    "        counts = rlt.get_counts(qc) \n",
    "        action = max(counts, key = counts.get)\n",
    "        nextPosition = self.newPosition(self.state, action) # handle the \n",
    "        reward = self.getReward(nextPosition)\n",
    "        # update q-table(but not very sure, update only for this action or for all actions)\n",
    "        targetQvalue = reward + self.gamma *  np.max(self.qt[nextPosition[0],nextPosition[1]])\n",
    "        predictedQvalue = self.calculateQvalue(action, nextPosition, reward, self.state)\n",
    "        \n",
    "        # update q-table\n",
    "        self.updateQtable(predictedQvalue, action)\n",
    "        return targetQvalue - self.qt[self.state.catP[0],self.state.catP[1]][int(action,2)]\n",
    "    \n",
    "    def updateQtable(self, predictedQvalue, action):\n",
    "        #if self.qt[(self.state.catP[0],self.state.catP[1])][int(action,2)] < predictedQvalue:\n",
    "            self.qt[self.state.catP[0],self.state.catP[1]][int(action,2)] = predictedQvalue\n",
    "\n",
    "    def calculateQvalue(self, action, nextPosition, reward, state:State):\n",
    "        targetQvalue = reward + self.gamma *  np.max(self.qt[nextPosition[0],nextPosition[1]])\n",
    "        return self.qt[state.catP[0], state.catP[1]][int(action,2)] + self.alpha * (targetQvalue - self.qt[state.catP[0],state.catP[1]][int(action,2)]) # update q-table\n",
    "\n",
    "    def updateCircuit(self, state:State):\n",
    "        self.rets[state.catP[0], state.catP[1]] = self.optimizer.optimize(num_vars=6, objective_function=self.lossFunction, initial_point=self.rets[state.catP[0], state.catP[1]][0])\n",
    "\n",
    "    def setAlpha(self, alpha):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def drawVectors(self, hasdiagonals):\n",
    "        # Draw vectors representing the cat's desired direction for each place in the grid based on the Qtable\n",
    "        x = np.linspace(0, self.gw.getNumColumns()-1, self.gw.getNumColumns())\n",
    "        y = np.linspace(0, self.gw.getNumColumns()-1, self.gw.getNumColumns())\n",
    "        vecx=np.zeros([len(x),len(y)])\n",
    "        vecy=np.zeros([len(x),len(y)])\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(y)):\n",
    "                vecx[i,j] = self.qt[(x[i], y[j])][3]-self.qt[(x[i], y[j])][2]\n",
    "                vecy[i,j] = self.qt[(x[i], y[j])][0]-self.qt[(x[i], y[j])][1]\n",
    "                norm = np.sqrt(vecx[i,j]**2 + vecy[i,j]**2)\n",
    "                vecx[i,j]=-vecx[i,j]/norm\n",
    "                vecy[i,j]=-vecy[i,j]/norm\n",
    "        pts = itertools.product(x, y)\n",
    "        plt.scatter(*zip(*pts), marker='o', s=30, color='red')\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        QP = plt.quiver(X, Y, vecx, vecy)\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent: cat\n",
    "class Cat:\n",
    "    def __init__(self, qNet: QNet, training=True, eps = 0.2, actions = [UP, DOWN, LEFT, RIGHT]):\n",
    "        self.eps = eps\n",
    "        self.training = training\n",
    "        self.qNet = qNet\n",
    "        self.ACTIONS = actions\n",
    "        self.state = None\n",
    "\n",
    "    def newPosition(self, state, action):\n",
    "            p = deepcopy(state.catP)\n",
    "            if action == UP:\n",
    "                p[0] = max(0, p[0] - 1)\n",
    "            elif action == DOWN:\n",
    "                p[0] = min(self.qNet.gw.getNumRows() - 1, p[0] + 1)\n",
    "            elif action == LEFT:\n",
    "                p[1] = max(0, p[1] - 1)\n",
    "            elif action == RIGHT:\n",
    "                p[1] = min(self.qNet.gw.getNumColumns() - 1, p[1] + 1)\n",
    "            else:\n",
    "                raise ValueError(f\"Unkown action {self.ACTIONS[action]}\")\n",
    "            return p\n",
    "\n",
    "    def getReward(self, p):\n",
    "        grid = self.qNet.gw.getItem(p)\n",
    "        if grid == MOUSE:\n",
    "            reward = 1000\n",
    "            end = True\n",
    "            self.qNet.gw.setCatP(p)\n",
    "        # elif grid == DOG:\n",
    "        #     reward = -100\n",
    "        #     end = True\n",
    "        #     self.qNet.gw.setCatP(p)\n",
    "        elif grid == EMPTY:\n",
    "            reward = -1\n",
    "            end = False\n",
    "            self.qNet.gw.setCatP(p)\n",
    "        elif grid == CAT:\n",
    "            reward = -1 # (maybe less than reward of empty)\n",
    "            end = False\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown grid item {grid}\")\n",
    "        return reward, end\n",
    "\n",
    "    def act(self, state, action):\n",
    "        p = self.newPosition(state, action)\n",
    "        reward, end = self.getReward(p)\n",
    "        return p, reward, end\n",
    "    \n",
    "    def updateQtable(self, action, p, reward, state):\n",
    "        pqv = self.qNet.calculateQvalue(action, p, reward, state)\n",
    "        self.qNet.updateQtable(pqv, action)\n",
    "\n",
    "    def setTraining(self, training):\n",
    "        self.Training = training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pet school\n",
    "class PetSchool:\n",
    "    def __init__(self, cat:Cat, numEpisodes, maxEpisodeSteps, training=True, minAlpha = 0.02, eps = 0.2):\n",
    "        self.cat = cat\n",
    "        self.training = training\n",
    "        self.NUM_EPISODES = numEpisodes\n",
    "        self.MAX_EPISODE_STEPS = maxEpisodeSteps\n",
    "        self.alphas = np.linspace(1.0, minAlpha, self.NUM_EPISODES)\n",
    "        self.eps = eps\n",
    "\n",
    "    def train(self):\n",
    "        counter = 0\n",
    "        for e in range(self.NUM_EPISODES): #  episode: a rund for agent\n",
    "            print(\"episode: \", e)\n",
    "            state = self.cat.qNet.gw.initCatState(rd=True) # default is rd = False\n",
    "            self.cat.qNet.setAlpha(self.alphas[e])\n",
    "            total_reward  = 0\n",
    "            step = 0\n",
    "            end = False\n",
    "            for _ in range(self.MAX_EPISODE_STEPS): # step: a time step for agent\n",
    "                action = self.cat.qNet.selectAction(deepcopy(state), self.training)\n",
    "                p, reward, end = self.cat.act(state, action)\n",
    "                # self.cat.updateQtable(action, p, reward, state)\n",
    "                total_reward += reward\n",
    "                step += 1\n",
    "                counter += 1\n",
    "                if end:\n",
    "                    print(\"catch the mouse!!!\")\n",
    "                    print(\"total reward: \", total_reward, \"steps: \", step)\n",
    "                    break\n",
    "        print(\"counter: \", counter)\n",
    "\n",
    "    def show(self):\n",
    "        self.cat.qNet.gw.show()\n",
    "        print(\"qTable: \", self.cat.qNet.qt)\n",
    "        print(\"\\nparams: \", self.cat.qNet.rets)\n",
    "        self.cat.qNet.drawVectors(False)\n",
    "\n",
    "    def initqTable(self, actions, size):\n",
    "        d = {}\n",
    "        for i in range(size[0]):\n",
    "            for j in range(size[1]):\n",
    "                d[i,j] = np.zeros(len(actions))\n",
    "        return d\n",
    "        \n",
    "    def mouseMove(p,oldPos): # goal (mouse) moves randomly with prob p every time the cat moves\n",
    "        side = 2 # Number of cells per side of the grid\n",
    "        if np.random.random() < p:\n",
    "            n = np.random.random()\n",
    "            if n < 0.25:\n",
    "                newPos = (max(0, oldPos[0]-1),oldPos[1])\n",
    "            elif n < 0.5:\n",
    "                newPos = (min(side - 1, oldPos[0]+1),oldPos[1])\n",
    "            elif n < 0.75:\n",
    "                newPos = (oldPos[0],max(0, oldPos[1]-1))\n",
    "            else:\n",
    "                newPos = (oldPos[0],min(side - 1, oldPos[1]+1))\n",
    "        else:\n",
    "            newPos = oldPos\n",
    "        return newPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super parameter\n",
    "gridSize = [3, 3]\n",
    "catP = [gridSize[0]-1, gridSize[0]-1]\n",
    "mouseP = [0, 0]\n",
    "EPS = 20\n",
    "MAX_EPS_STEP = 30\n",
    "sizeOfParams = 6\n",
    "gamma = 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\qiskit\\utils\\deprecation.py:62: DeprecationWarning: Using a qobj for run() is deprecated as of qiskit-aer 0.9.0 and will be removed no sooner than 3 months from that release date. Transpiled circuits should now be passed directly using `backend.run(circuits, **run_options).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catch the mouse!!!\n",
      "total reward:  1000 steps:  1\n",
      "episode:  1\n",
      "episode:  2\n",
      "episode:  3\n",
      "catch the mouse!!!\n",
      "total reward:  988 steps:  13\n",
      "episode:  4\n",
      "episode:  5\n",
      "episode:  6\n",
      "episode:  7\n",
      "episode:  8\n",
      "episode:  9\n",
      "episode:  10\n",
      "catch the mouse!!!\n",
      "total reward:  1000 steps:  1\n",
      "episode:  11\n",
      "catch the mouse!!!\n",
      "total reward:  1000 steps:  1\n",
      "episode:  12\n",
      "episode:  13\n",
      "episode:  14\n",
      "episode:  15\n",
      "catch the mouse!!!\n",
      "total reward:  1000 steps:  1\n",
      "episode:  16\n",
      "episode:  17\n",
      "episode:  18\n",
      "episode:  19\n",
      "counter:  467\n"
     ]
    }
   ],
   "source": [
    "def initqTable(size, actions=[UP, DOWN, LEFT, RIGHT]):\n",
    "    d = {}\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            d[i,j] = np.zeros(len(actions))\n",
    "    return d\n",
    "\n",
    "# initGridWorld\n",
    "gridWorld = GridWorld(gridSize, catP=catP, mouseP=mouseP)\n",
    "# init parameter\n",
    "initialParameters = np.zeros(sizeOfParams)\n",
    "# init q Table\n",
    "qt = initqTable(gridSize)\n",
    "# init q Circuit\n",
    "qNet = QNet(qt, gridWorld, initialParameters, gamma=gamma)\n",
    "# init cat\n",
    "cat = Cat(qNet=qNet)\n",
    "# init pet school\n",
    "petSchool = PetSchool(cat, EPS, MAX_EPS_STEP)\n",
    "# start training\n",
    "petSchool.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m emp emp \n",
      "emp emp emp \n",
      "emp c emp \n",
      "\n",
      "qTable:  {(0, 0): array([0., 0., 0., 0.]), (0, 1): array([-1.,  0.,  0.,  0.]), (0, 2): array([0., 0., 0., 0.]), (1, 0): array([100.,   0.,   0.,   0.]), (1, 1): array([-1.,  0.,  0.,  0.]), (1, 2): array([-1.,  0.,  0.,  0.]), (2, 0): array([97.        , 89.20848412, 94.06      ,  0.        ]), (2, 1): array([-1.,  0.,  0.,  0.]), (2, 2): array([-1.,  0.,  0.,  0.])}\n",
      "\n",
      "params:  {(0, 0): (array([0., 0., 0., 0., 0., 0.]), 0.0, 0), (0, 1): (array([ 8.00381759e-05,  3.51875428e-05,  4.20063864e-05, -1.34706847e-05,\n",
      "        1.83195352e-05,  8.60964694e-06]), 0.0, 37), (0, 2): (array([0., 0., 0., 0., 0., 0.]), 0.0, 0), (1, 0): (array([0., 0., 0., 0., 0., 0.]), 0.0, 37), (1, 1): (array([ 1.43684022e-04,  4.47980283e-05, -2.42439378e-04, -2.17786475e-04,\n",
      "        1.71117014e-04,  7.76447458e-05]), -2.1405099914773018e-13, 52), (1, 2): (array([4.87501183e-05, 7.18321735e-05, 2.68869100e-05, 2.89293858e-05,\n",
      "       2.22941605e-05, 2.01672985e-05]), 0.0, 37), (2, 0): (array([-0.02332911,  1.45054987,  1.4877359 ,  1.27548996,  1.48778515,\n",
      "        1.27549177]), 0.0, 37), (2, 1): (array([ 4.01719973e-05,  4.29463347e-05, -5.70137791e-05, -1.10647642e-05,\n",
      "        3.48773488e-05, -4.41858971e-05]), 0.0, 37), (2, 2): (array([ 1.18968626e-05,  5.49913574e-05, -4.93121553e-05,  2.15784768e-06,\n",
      "       -6.41341067e-05,  1.68785859e-05]), 0.0, 37)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:115: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:116: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show what have been learned\n",
    "petSchool.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11ffc019a02cc0e21e59860b66c88ea81995ce9237607e8ab2c087a287ee4867"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
