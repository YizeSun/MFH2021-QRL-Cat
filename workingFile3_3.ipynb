{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister\n",
    "from qiskit import Aer, transpile, assemble\n",
    "from qiskit.providers import backend\n",
    "from qiskit.aqua.components.optimizers import COBYLA\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TYPES:\n",
    "CAT = \"c\"\n",
    "# DOG = \"d\"\n",
    "MOUSE = \"m\"\n",
    "EMPTY = \"emp\"\n",
    "\n",
    "# ACTIONS:\n",
    "UP = \"00\"\n",
    "DOWN = \"01\"\n",
    "LEFT = \"10\"\n",
    "RIGHT = \"11\"\n",
    "ACTIONS = [UP, DOWN, LEFT, RIGHT]\n",
    "\n",
    "# random seed\n",
    "random.seed(10)\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state of cat\n",
    "class State:\n",
    "    def __init__(self, catP):\n",
    "        self.row = catP[0]\n",
    "        self.column = catP[1]\n",
    "        self.catP = catP\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, State) and self.row == other.row and self.column == other.column and self.catP == other.catP\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(str(self.catP))\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"State(cat_pos={self.catP})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridWorld\n",
    "# e.g.\n",
    "#  MOUSE | EMPTY | EMPTY\n",
    "#  EMPTY | EMPTY | EMPTY\n",
    "#  EMPTY | EMPTY | CAT\n",
    "class GridWorld:\n",
    "    def __init__(self, s, catP, mouseP):\n",
    "        self.numRows = s[0]\n",
    "        self.numColumns = s[1]\n",
    "        self.catP = catP\n",
    "        self.mouseP = mouseP\n",
    "        # self.dogP = dogP\n",
    "        assert(not self.compaireList(self.catP, self.mouseP))\n",
    "    \n",
    "    def getItem(self, p):\n",
    "        if p[0]>=self.numRows or p[0]<0:\n",
    "            return None\n",
    "        if p[1]>=self.numColumns or p[1]<0:\n",
    "            return None\n",
    "        if self.compaireList(p, catP):\n",
    "            return CAT\n",
    "        elif self.compaireList(p, mouseP):\n",
    "            return MOUSE\n",
    "        # elif self.compaireList(p, DOG):\n",
    "        #     return DOG\n",
    "        else:\n",
    "            return EMPTY\n",
    "\n",
    "    def compaireList(self, l1,l2):\n",
    "        for i, j in zip(l1, l2):\n",
    "            if i!=j:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def getNumRows(self):\n",
    "        return self.numRows\n",
    "\n",
    "    def getNumColumns(self):\n",
    "        return self.numColumns\n",
    "\n",
    "    def getMouse(self):\n",
    "        return self.mouse\n",
    "    \n",
    "    def getCatP(self):\n",
    "        return self.catP\n",
    "\n",
    "    def setCatP(self, p):\n",
    "        self.catP = p\n",
    "        \n",
    "    def setMouseP(self, p):\n",
    "        self.mouseP = p\n",
    "    \n",
    "    def initCatState(self, rd = False):\n",
    "        # init cat position\n",
    "        if not rd:\n",
    "            catP = [self.getNumRows() - 1, self.getNumColumns() - 1]\n",
    "        else:\n",
    "            catP = [random.randint(0, self.getNumRows()), random.randint(0, self.getNumColumns())]\n",
    "            while self.getItem(catP) != EMPTY and self.getItem(catP) != CAT:\n",
    "                catP = [random.randint(0, self.getNumRows()), random.randint(0, self.getNumColumns())]\n",
    "        self.setCatP(catP)\n",
    "        return State(catP)\n",
    "    \n",
    "    def show(self):\n",
    "        output = \"\"\n",
    "        for i in range(self.numRows):\n",
    "            for j in range(self.numColumns):\n",
    "                if self.compaireList([i,j], self.catP):\n",
    "                    output += CAT + \" \"\n",
    "                if self.compaireList([i,j], self.mouseP):\n",
    "                    output += MOUSE + \" \"\n",
    "                if not self.compaireList([i,j], self.catP) and not self.compaireList([i,j], self.mouseP):\n",
    "                    output += EMPTY + \" \"\n",
    "            output += \"\\n\"\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QNet\n",
    "class QNet:\n",
    "    \n",
    "    def __init__(self, qTable, gridWorld:GridWorld, params, alpha=0.1, gamma=1.0, eps=0.2, actions=[UP, DOWN, LEFT, RIGHT]):\n",
    "        \n",
    "        self.params = params # inital parameters are the same for all qNetwork\n",
    "        self.gw = gridWorld\n",
    "        self.qt = qTable\n",
    "        self.eps = eps\n",
    "        self.backend = Aer.get_backend(\"qasm_simulator\")\n",
    "        self.NUM_SHOTS = 1000 # number of measurements \n",
    "        self.optimizer = COBYLA(maxiter=500, tol=0.0001) # off the shelf\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.ACTIONS = actions\n",
    "\n",
    "        # self.rets = {(0,0):([0,..,0],0.0,0), ...}\n",
    "        self.rets = dict() # resulting parameters after optimization for all points in the grid\n",
    "\n",
    "        self.state = None\n",
    "        \n",
    "        for i in range(self.gw.getNumRows()):\n",
    "            for j in range(self.gw.getNumColumns()):\n",
    "                self.rets[i, j] = (self.params, 0.0, 0) \n",
    "    \n",
    "    def qcMaker(self, params):\n",
    "        qr = QuantumRegister(2, name=\"q\")\n",
    "        cr = ClassicalRegister(2, name=\"c\")\n",
    "        qc = QuantumCircuit(qr, cr)\n",
    "        qc.u3(params[0], params[1], params[2], qr[0])\n",
    "        qc.u3(params[3], params[4], params[5], qr[1])\n",
    "        # qc.cx(qr[0], qr[1])\n",
    "        qc.measure(qr, cr)\n",
    "        return qc\n",
    "\n",
    "    def newPosition(self, state, action):\n",
    "        p = deepcopy(state.catP)\n",
    "        if action == UP:\n",
    "            p[0] = max(0, p[0] - 1)\n",
    "        elif action == DOWN:\n",
    "            p[0] = min(self.gw.getNumRows() - 1, p[0]+1)\n",
    "        elif action == LEFT:\n",
    "            p[1] = max(0, p[1] - 1)\n",
    "        elif action == RIGHT:\n",
    "            p[1] = min(self.gw.getNumColumns() - 1, p[1] + 1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unkown action {action}\")\n",
    "        return p\n",
    "        \n",
    "    def getReward(self, p):\n",
    "        grid = self.gw.getItem(p)\n",
    "        if grid == EMPTY:\n",
    "            reward = -1\n",
    "        # elif grid == DOG:\n",
    "        #     reward = -1000\n",
    "        elif grid == MOUSE:\n",
    "            reward = 100\n",
    "        elif grid == CAT:\n",
    "            reward = -1 # (maybe less than reward of empty)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown grid item {grid}\")\n",
    "        return reward\n",
    "    \n",
    "    def selectAction(self, state, training):\n",
    "        if random.uniform(0, 1) < self.eps:\n",
    "            return random.choice(self.ACTIONS)\n",
    "        else:\n",
    "            if training:\n",
    "                self.state = state\n",
    "                self.updateCircuit(state)\n",
    "            return self.ACTIONS[np.argmax(self.qt[self.state.catP[0], self.state.catP[1]])]\n",
    "        \n",
    "    def lossFunction(self, params):\n",
    "        qc = self.qcMaker(params=params)\n",
    "        t_qc = transpile(qc, self.backend)\n",
    "        job = assemble(t_qc, shots=self.NUM_SHOTS)\n",
    "        rlt = self.backend.run(job).result()\n",
    "        counts = rlt.get_counts(qc) \n",
    "        action = max(counts, key = counts.get)\n",
    "        nextPosition = self.newPosition(self.state, action) # handle the \n",
    "        reward = self.getReward(nextPosition)\n",
    "        # update q-table(but not very sure, update only for this action or for all actions)\n",
    "        targetQvalue = reward + self.gamma *  np.max(self.qt[nextPosition[0],nextPosition[1]])\n",
    "        predictedQvalue = self.calculateQvalue(action, nextPosition, reward, self.state)\n",
    "        \n",
    "        # update q-table\n",
    "        self.updateQtable(predictedQvalue, action)\n",
    "        return targetQvalue - self.qt[self.state.catP[0],self.state.catP[1]][int(action,2)]\n",
    "    \n",
    "    def updateQtable(self, predictedQvalue, action):\n",
    "        if self.qt[(self.state.catP[0],self.state.catP[1])][int(action,2)] < predictedQvalue:\n",
    "            self.qt[self.state.catP[0],self.state.catP[1]][int(action,2)] = predictedQvalue\n",
    "\n",
    "    def calculateQvalue(self, action, nextPosition, reward, state:State):\n",
    "        targetQvalue = reward + self.gamma *  np.max(self.qt[nextPosition[0],nextPosition[1]])\n",
    "        return self.qt[state.catP[0], state.catP[1]][int(action,2)] + self.alpha * (targetQvalue - self.qt[state.catP[0],state.catP[1]][int(action,2)]) # update q-table\n",
    "\n",
    "    def updateCircuit(self, state:State):\n",
    "        self.rets[state.catP[0], state.catP[1]] = self.optimizer.optimize(num_vars=6, objective_function=self.lossFunction, initial_point=self.rets[state.catP[0], state.catP[1]][0])\n",
    "\n",
    "    def setAlpha(self, alpha):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def drawVectors(self, hasdiagonals):\n",
    "        # Draw vectors representing the cat's desired direction for each place in the grid based on the Qtable\n",
    "        x = np.linspace(0, self.gw.getNumColumns()-1, self.gw.getNumColumns())\n",
    "        y = np.linspace(0, self.gw.getNumColumns()-1, self.gw.getNumColumns())\n",
    "        vecx=np.zeros([len(x),len(y)])\n",
    "        vecy=np.zeros([len(x),len(y)])\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(y)):\n",
    "                vecx[i,j] = self.qt[(x[i], y[j])][3]-self.qt[(x[i], y[j])][2]\n",
    "                vecy[i,j] = self.qt[(x[i], y[j])][0]-self.qt[(x[i], y[j])][1]\n",
    "                norm = vecx[i,j]**2 + vecy[i,j]**2\n",
    "                vecx[i,j]=vecx[i,j]/norm\n",
    "                vecy[i,j]=vecy[i,j]/norm\n",
    "        pts = itertools.product(x, y)\n",
    "        plt.scatter(*zip(*pts), marker='o', s=30, color='red')\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        QP = plt.quiver(X, Y, vecx, vecy)\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent: cat\n",
    "class Cat:\n",
    "    def __init__(self, qNet: QNet, training=True, eps = 0.2, actions = [UP, DOWN, LEFT, RIGHT]):\n",
    "        self.eps = eps\n",
    "        self.training = training\n",
    "        self.qNet = qNet\n",
    "        self.ACTIONS = actions\n",
    "        self.state = None\n",
    "\n",
    "    def newPosition(self, state, action):\n",
    "            p = deepcopy(state.catP)\n",
    "            if action == UP:\n",
    "                p[0] = max(0, p[0] - 1)\n",
    "            elif action == DOWN:\n",
    "                p[0] = min(self.qNet.gw.getNumRows() - 1, p[0] + 1)\n",
    "            elif action == LEFT:\n",
    "                p[1] = max(0, p[1] - 1)\n",
    "            elif action == RIGHT:\n",
    "                p[1] = min(self.qNet.gw.getNumColumns() - 1, p[1] + 1)\n",
    "            else:\n",
    "                raise ValueError(f\"Unkown action {self.ACTIONS[action]}\")\n",
    "            return p\n",
    "\n",
    "    def getReward(self, p):\n",
    "        grid = self.qNet.gw.getItem(p)\n",
    "        if grid == MOUSE:\n",
    "            reward = 1000\n",
    "            end = True\n",
    "            self.qNet.gw.setCatP(p)\n",
    "        # elif grid == DOG:\n",
    "        #     reward = -100\n",
    "        #     end = True\n",
    "        #     self.qNet.gw.setCatP(p)\n",
    "        elif grid == EMPTY:\n",
    "            reward = -1\n",
    "            end = False\n",
    "            self.qNet.gw.setCatP(p)\n",
    "        elif grid == CAT:\n",
    "            reward = -1 # (maybe less than reward of empty)\n",
    "            end = False\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown grid item {grid}\")\n",
    "        return reward, end\n",
    "\n",
    "    def act(self, state, action):\n",
    "        p = self.newPosition(state, action)\n",
    "        reward, end = self.getReward(p)\n",
    "        return p, reward, end\n",
    "    \n",
    "    def updateQtable(self, action, p, reward, state):\n",
    "        pqv = self.qNet.calculateQvalue(action, p, reward, state)\n",
    "        self.qNet.updateQtable(pqv, action)\n",
    "\n",
    "    def setTraining(self, training):\n",
    "        self.Training = training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pet school\n",
    "class PetSchool:\n",
    "    def __init__(self, cat:Cat, numEpisodes, maxEpisodeSteps, training=True, minAlpha = 0.02, eps = 0.2):\n",
    "        self.cat = cat\n",
    "        self.training = training\n",
    "        self.NUM_EPISODES = numEpisodes\n",
    "        self.MAX_EPISODE_STEPS = maxEpisodeSteps\n",
    "        self.alphas = np.linspace(1.0, minAlpha, self.NUM_EPISODES)\n",
    "        self.eps = eps\n",
    "\n",
    "    def train(self):\n",
    "        counter = 0\n",
    "        for e in range(self.NUM_EPISODES): #  episode: a rund for agent\n",
    "            print(\"episode: \", e)\n",
    "            state = self.cat.qNet.gw.initCatState(rd=True) # default is rd = False\n",
    "            self.cat.qNet.setAlpha(self.alphas[e])\n",
    "            total_reward  = 0\n",
    "            step = 0\n",
    "            end = False\n",
    "            for _ in range(self.MAX_EPISODE_STEPS): # step: a time step for agent\n",
    "                action = self.cat.qNet.selectAction(deepcopy(state), self.training)\n",
    "                p, reward, end = self.cat.act(state, action)\n",
    "                # self.cat.updateQtable(action, p, reward, state)\n",
    "                total_reward += reward\n",
    "                step += 1\n",
    "                counter += 1\n",
    "                if end:\n",
    "                    print(\"catch the mouse!!!\")\n",
    "                    print(\"total reward: \", total_reward, \"steps: \", step)\n",
    "                    break\n",
    "        print(\"counter: \", counter)\n",
    "\n",
    "    def show(self):\n",
    "        self.cat.qNet.gw.show()\n",
    "        print(\"qTable: \", self.cat.qNet.qt)\n",
    "        print(\"\\nparams: \", self.cat.qNet.rets)\n",
    "        self.cat.qNet.drawVectors(False)\n",
    "\n",
    "    def initqTable(self, actions, size):\n",
    "        d = {}\n",
    "        for i in range(size[0]):\n",
    "            for j in range(size[1]):\n",
    "                d[i,j] = np.zeros(len(actions))\n",
    "        return d\n",
    "        \n",
    "    def mouseMove(p,oldPos): # goal (mouse) moves randomly with prob p every time the cat moves\n",
    "        side = 2 # Number of cells per side of the grid\n",
    "        if np.random.random() < p:\n",
    "            n = np.random.random()\n",
    "            if n < 0.25:\n",
    "                newPos = (max(0, oldPos[0]-1),oldPos[1])\n",
    "            elif n < 0.5:\n",
    "                newPos = (min(side - 1, oldPos[0]+1),oldPos[1])\n",
    "            elif n < 0.75:\n",
    "                newPos = (oldPos[0],max(0, oldPos[1]-1))\n",
    "            else:\n",
    "                newPos = (oldPos[0],min(side - 1, oldPos[1]+1))\n",
    "        else:\n",
    "            newPos = oldPos\n",
    "        return newPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super parameter\n",
    "gridSize = [3, 3]\n",
    "catP = [gridSize[0]-1, gridSize[0]-1]\n",
    "mouseP = [0, 0]\n",
    "EPS = 20\n",
    "MAX_EPS_STEP = 30\n",
    "sizeOfParams = 6\n",
    "gamma = 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0\n",
      "catch the mouse!!!\n",
      "total reward:  1000 steps:  1\n",
      "episode:  1\n",
      "episode:  2\n",
      "episode:  3\n",
      "catch the mouse!!!\n",
      "total reward:  988 steps:  13\n",
      "episode:  4\n",
      "episode:  5\n",
      "episode:  6\n",
      "episode:  7\n",
      "episode:  8\n",
      "episode:  9\n",
      "episode:  10\n",
      "catch the mouse!!!\n",
      "total reward:  1000 steps:  1\n",
      "episode:  11\n",
      "catch the mouse!!!\n",
      "total reward:  1000 steps:  1\n",
      "episode:  12\n",
      "episode:  13\n",
      "episode:  14\n",
      "episode:  15\n",
      "catch the mouse!!!\n",
      "total reward:  1000 steps:  1\n",
      "episode:  16\n",
      "episode:  17\n",
      "episode:  18\n",
      "episode:  19\n",
      "counter:  467\n"
     ]
    }
   ],
   "source": [
    "def initqTable(size, actions=[UP, DOWN, LEFT, RIGHT]):\n",
    "    d = {}\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            d[i,j] = np.zeros(len(actions))\n",
    "    return d\n",
    "\n",
    "# initGridWorld\n",
    "gridWorld = GridWorld(gridSize, catP=catP, mouseP=mouseP)\n",
    "# init parameter\n",
    "initialParameters = np.zeros(sizeOfParams)\n",
    "# init q Table\n",
    "qt = initqTable(gridSize)\n",
    "# init q Circuit\n",
    "qNet = QNet(qt, gridWorld, initialParameters, gamma=gamma)\n",
    "# init cat\n",
    "cat = Cat(qNet=qNet)\n",
    "# init pet school\n",
    "petSchool = PetSchool(cat, EPS, MAX_EPS_STEP)\n",
    "# start training\n",
    "petSchool.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m c emp \n",
      "emp emp emp \n",
      "emp emp emp \n",
      "\n",
      "qTable:  {(0, 0): array([0., 0., 0., 0.]), (0, 1): array([0., 0., 0., 0.]), (0, 2): array([0., 0., 0., 0.]), (1, 0): array([100.,   0.,   0.,   0.]), (1, 1): array([0., 0., 0., 0.]), (1, 2): array([0., 0., 0., 0.]), (2, 0): array([97.        , 89.20848412, 94.06      ,  0.        ]), (2, 1): array([0., 0., 0., 0.]), (2, 2): array([0., 0., 0., 0.])}\n",
      "\n",
      "params:  {(0, 0): (array([0., 0., 0., 0., 0., 0.]), 0.0, 0), (0, 1): (array([0., 0., 0., 0., 0., 0.]), -1.0, 37), (0, 2): (array([0., 0., 0., 0., 0., 0.]), 0.0, 0), (1, 0): (array([0., 0., 0., 0., 0., 0.]), 0.0, 37), (1, 1): (array([0., 0., 0., 0., 0., 0.]), -1.0, 37), (1, 2): (array([0., 0., 0., 0., 0., 0.]), -1.0, 37), (2, 0): (array([-0.02332911,  1.45054987,  1.4877359 ,  1.27548996,  1.48778515,\n",
      "        1.27549177]), 0.0, 37), (2, 1): (array([0., 0., 0., 0., 0., 0.]), -1.0, 37), (2, 2): (array([0., 0., 0., 0., 0., 0.]), -1.0, 37)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:115: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:116: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show what have been learned\n",
    "petSchool.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11ffc019a02cc0e21e59860b66c88ea81995ce9237607e8ab2c087a287ee4867"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
